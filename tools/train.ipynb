{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e50620f-5e15-4482-bd62-437ac9ff3d94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\skber\\miniconda3\\envs\\mobilenet-v2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os, zipfile, io, re\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import models\n",
    "from torchvision.models.mobilenetv2 import MobileNet_V2_Weights\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tensorboardX import SummaryWriter\n",
    "os.chdir('C:/Users/skber/work/01_Defios/01_研修/FacialGenderNet')\n",
    "# GPUが利用可能かどうかをチェック\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f7f9787-70e2-477d-95e6-4951d916816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 128\n",
    "classes = [\"male\", \"female\"]\n",
    "num_classes = len(classes)\n",
    "zdata_path = './dataset/UTKFace_test.zip'\n",
    "result_dir = \"Result/try1\"\n",
    "num_classes = 2  # クラス数を設定\n",
    "num_epochs =50\n",
    "\n",
    "# ZIP読み込み\n",
    "z_train = zipfile.ZipFile(zdata_path) # UTKFace_test.zip にしてる\n",
    "# 画像ファイルパスのみ取得\n",
    "imgfiles = [ x for x in z_train.namelist() if re.search(r\".*jpg$\", x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5f20cce-91bb-40ff-ad4f-d47e7ce4df7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 4820/4820 [01:02<00:00, 76.63it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "print(\"load dataset\")\n",
    "for imgfile in tqdm(imgfiles):\n",
    "    # ZIPから画像読み込み\n",
    "    image = Image.open(io.BytesIO(z_train.read(imgfile)))\n",
    "    # RGB変換\n",
    "    image = image.convert('RGB')\n",
    "    # リサイズ\n",
    "    image = image.resize((image_size, image_size))\n",
    "    # 画像から配列に変換\n",
    "    data = np.asarray(image)\n",
    "    file = os.path.basename(imgfile)\n",
    "    file_split = [i for i in file.split('_')]\n",
    "    X.append(data)\n",
    "    Y.append(file_split[1])\n",
    "z_train.close()\n",
    "del z_train, imgfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7484d67-acec-4676-84e1-a34baaf492c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor変換\n",
    "X_np = np.array(X)\n",
    "Y_np = np.array(Y, dtype=int)\n",
    "X = torch.tensor(X_np)\n",
    "Y_tensor = torch.tensor(Y_np, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "685d553d-100c-4efd-ae87-71abadbe29a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# データ型の変換＆正規化\n",
    "X_train = X.to(torch.float32) / 255\n",
    "# one-hot変換\n",
    "y_train = F.one_hot(Y_tensor, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "501d2a9f-6375-42ef-b6a2-09a00c9246f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:torch.Size([1973, 128, 128, 3]), y_train:torch.Size([1973, 2]), X_valid:torch.Size([494, 128, 128, 3]), y_valid:torch.Size([494, 2])\n"
     ]
    }
   ],
   "source": [
    "# trainデータからvalidデータを分割\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    random_state = 42,\n",
    "    stratify = y_train,\n",
    "    test_size = 0.2\n",
    ")\n",
    "print(f\"X_train:{X_train.shape}, y_train:{y_train.shape}, X_valid:{X_valid.shape}, y_valid:{y_valid.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64ee07c2-6294-4146-bc4b-fc11c9d451e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNetV2モデルの読み込み（修正版）\n",
    "weights = MobileNet_V2_Weights.IMAGENET1K_V1  # または MobileNet_V2_Weights.DEFAULT\n",
    "model = models.mobilenet_v2(weights=weights)\n",
    "\n",
    "# すべての層をトレーニング可能にする\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de7a9d04-85f8-4bc4-8016-c4e2934d6e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    # 必要に応じて他の変換を追加\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5d4154a-45bd-4173-b9b4-98dbb06eb508",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EarlyStopping クラスの実装\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                if self.verbose:\n",
    "                    print(\"Early stopping\")\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "# Early stopping 設定\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "# ModelCheckpointの実装\n",
    "def save_checkpoint(state, filename):\n",
    "    # ディレクトリのパスを取得\n",
    "    dir_name = os.path.dirname(filename)\n",
    "    # ディレクトリが存在しない場合は作成\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    # チェックポイントを保存\n",
    "    torch.save(state, filename)\n",
    "\n",
    "# ReduceLROnPlateauの初期化\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38b4c8f1-ccd5-4b60-81fc-62cdafb3e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"{result_dir}/tf_log\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "# SummaryWriterのインスタンスを作成\n",
    "writer = SummaryWriter(log_dir=f\"{result_dir}/tf_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bc6de78-3cb4-44df-b7c0-a152c9e89aac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# データセットの変換\n",
    "X_train = torch.stack([transform(x) for x in X_train])\n",
    "X_valid = torch.stack([transform(x) for x in X_valid])\n",
    "# データセットとDataLoaderの設定\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_dataset = TensorDataset(X_valid, y_valid)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f51761b1-63c9-4f80-bf6d-e8592cb41d45",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory Result/try1/weights does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# チェックポイントの保存\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 50\u001b[0m     \u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptimizer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mresult_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/weights/epoch\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pth.tar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# TensorBoardへのログ記録\u001b[39;00m\n\u001b[0;32m     57\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss/train\u001b[39m\u001b[38;5;124m'\u001b[39m, train_loss, epoch)\n",
      "Cell \u001b[1;32mIn[13], line 28\u001b[0m, in \u001b[0;36msave_checkpoint\u001b[1;34m(state, filename)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_checkpoint\u001b[39m(state, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/checkpoint.pth.tar\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 28\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\movilenet-v2\\lib\\site-packages\\torch\\serialization.py:440\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    437\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\movilenet-v2\\lib\\site-packages\\torch\\serialization.py:315\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\movilenet-v2\\lib\\site-packages\\torch\\serialization.py:288\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Parent directory Result/try1/weights does not exist."
     ]
    }
   ],
   "source": [
    "# トレーニングループ\n",
    "# モデルをデバイスに移動\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):  # num_epochsは設定するエポック数\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, targets in train_loader: \n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        if targets.dim() > 1:\n",
    "            targets = targets.argmax(dim=1)\n",
    "        inputs = inputs.permute(0, 3, 1, 2)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # 平均トレーニング損失\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # 検証ループ\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    valid_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in valid_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            if targets.dim() > 1:\n",
    "                targets = targets.argmax(dim=1)\n",
    "            inputs = inputs.permute(0, 3, 1, 2)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            valid_loss += loss.item()\n",
    "            # 正解率の計算（必要に応じて）\n",
    "\n",
    "    # 平均検証損失\n",
    "    valid_loss /= len(valid_loader)\n",
    "    # Early StoppingとLearning Rate Schedulerの呼び出し\n",
    "    early_stopping(valid_loss)\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    # Early Stoppingのチェック\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "    # チェックポイントの保存\n",
    "    if epoch % 3 == 0:\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, filename= f\"{result_dir}/weights/epoch{epoch}.pth.tar\")\n",
    "\n",
    "    # TensorBoardへのログ記録\n",
    "    writer.add_scalar(f'{result_dir}/Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar(f'{result_dir}/Loss/val', valid_loss, epoch)\n",
    "    # エポックごとの進捗の表示\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss}, Valid Loss: {valid_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16567470-5d5e-49a2-9398-819998c3ab00",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'writer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# SummaryWriterのリソースを解放\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'writer' is not defined"
     ]
    }
   ],
   "source": [
    "# SummaryWriterのリソースを解放\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855f6a0d-43f3-4806-8c43-c4a09b95a372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
